# Project Euler 898 Solution - Claire Voyant

<https://projecteuler.net/problem=898>:

* [898.py](898.py)

## Core idea: Bayes-optimal guessing
Each student reports **H** or **T** after seeing the true coin toss. Student *i* lies independently with known probability \(p_i\).

For any full set of reports \(r\), the two likelihoods are

- \(L_H(r)=P(r\mid\text{Heads})\)
- \(L_T(r)=P(r\mid\text{Tails})\)

With an a-priori fair coin, the optimal strategy is the **likelihood-ratio test**:

- guess **Heads** iff \(L_H(r)\ge L_T(r)\), otherwise guess **Tails**.

The resulting success probability can be written as

\[
P(\text{correct})=\tfrac12\sum_r \max\bigl(L_H(r),L_T(r)\bigr)
=\tfrac12\bigl(1+\operatorname{TV}(L_H,L_T)\bigr),
\]

where \(\operatorname{TV}\) is the total variation distance between the two report distributions.

## Likelihood ratio as a product
For one student with lie probability \(p\):

- If they say **H**, the likelihood ratio contributes \((1-p)/p\)
- If they say **T**, it contributes the reciprocal

So the overall likelihood ratio (LR) is a product of simple rational factors.
The decision boundary \(L_H\ge L_T\) is exactly **LR \(\ge 1\)**.

## Pairing complementary probabilities
In the target instance the lie probabilities are \(25\%,26\%,\dots,75\%\), which contains complementary pairs \(p\) and \(1-p\) (plus a single uninformative \(50\%\)).

Pairing \(p\) with \(1-p\) collapses two students into a single independent variable with **three** possible LR factors:

- \(\bigl((1-p)/p\bigr)^2\)
- \(1\)
- \(\bigl(p/(1-p)\bigr)^2\)

This reduces the problem from 51 binary variables to 25 ternary variables.

## Meet-in-the-middle
Even with 25 ternary variables, enumerating all \(3^{25}\) outcomes is too large.
Instead we split the variables into two halves:

1. Enumerate all outcomes in the right half and store their LR values and probabilities.
2. Sort the right-half outcomes by LR and build **suffix sums** of probabilities.
3. Enumerate all outcomes in the left half; for each left LR value, binary-search the right list to count how much probability mass makes the combined LR \(\ge 1\).

This computes

- \(P(\text{LR}\ge 1\mid\text{Heads})\)
- \(P(\text{LR}\ge 1\mid\text{Tails})\)

and therefore the optimal success probability.

## Exact ordering without floating point comparisons
LR values are rational numbers. To sort and binary-search them *robustly*, the implementation maps each LR \(=n/d\) to a **fixed-point integer key**

\[
K = \left\lfloor \frac{n}{d}\,2^{\text{SHIFT}} \right\rfloor
\]

Choosing `SHIFT` large enough (bigger than twice the bit-length bound on denominators) makes this mapping injective over all fractions that can occur, so ordering by `K` matches exact rational ordering.

## Complexity
Let \(m\approx 25\) be the number of paired variables.
Splitting roughly in half gives about \(3^{m/2}\) states per side:

- Time: \(O(3^{m/2}\log 3^{m/2})\) dominated by sorting
- Memory: \(O(3^{m/2})\)

This is easily fast enough in pure Python for the given input size.
