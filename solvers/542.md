# Project Euler 542 Solution - Geometric Progression with Maximum Sum

<https://projecteuler.net/problem=542>:

* [542.py](542.py)

We need:

- `S(k)`: the **maximum** possible sum of **≥ 3 distinct positive integers** not exceeding `k` that form a **geometric progression** (GP).
- `T(n) = Σ_{k=4..n} (-1)^k · S(k)`
- Compute `T(10^17)`.

## 1) Normalizing the geometric progression

Let the GP (in increasing order) be:

`a0, a1, ..., at` with `t ≥ 2` and ratio `r > 1`.

Write the ratio as a reduced fraction `r = p/q` with `gcd(p, q)=1`.  
The GP condition is:

`a_{i+1} = a_i * p / q` and all `a_i` are integers.

From integrality, `q^t` must divide the first term. We can parametrize:

- choose integers `p > q ≥ 1`, `t ≥ 2`, `b ≥ 1`
- then the GP is:

`b*q^t, b*q^{t-1}*p, ..., b*p^t`

Its sum is:

`b * Σ_{i=0..t} p^i q^{t-i} = b * (p^{t+1} - q^{t+1}) / (p - q)`

The largest term is `b * p^t`, so the constraint “no value exceeds `k`” becomes:

`b * p^t ≤ k  =>  b ≤ floor(k / p^t)`

For any fixed `(p,q,t)`, the best scaling is therefore `b = floor(k / p^t)`.

## 2) Why `q = p - 1` is always optimal

For fixed `p` and `t`, increasing `q` (keeping `q < p`) makes every term larger while the maximum term `b*p^t` stays unchanged.

Because `gcd(p, p-1) = 1`, the largest possible `q` is always `q = p - 1`.

So we only need to consider ratios `p/(p-1)`.

With `q = p - 1`:

- largest term: `b * p^t`
- sum: `b * (p^{t+1} - (p-1)^{t+1})`

Thus:

`S(k) = max_{p ≥ 2, t ≥ 2} floor(k / p^t) · (p^{t+1} - (p-1)^{t+1})`

## 3) Computing `S(k)` fast with pruning

Directly checking all `p` for small `t` can be huge, but we can prune heavily using a simple bound:

A GP of length `t+1` has sum `< (t+1)·k` because every term is ≤ `k`.

Also the “sum per max-term” coefficient is `< p`, so with `p^t ≤ k` we also have `< p·k`.

So for each `t`:

`S(k) ≤ min(t+1, floor(k^{1/t})) · k`

During the search, once we have a current best value `best`, any `(t)` whose bound is `≤ best` can be skipped.
When the bound becomes `(t+1)·k ≤ best`, **all smaller t** can be skipped too (the bound only decreases).

In practice, for large `k` this prevents ever iterating over the enormous ranges for `t=2` or `t=3`.

## 4) Turning `T(n)` into a small number of interval contributions

`S(k)` is **nondecreasing** and stays **constant on long intervals** (it changes only when a better GP becomes possible).

We exploit this:

1. At position `k`, compute `v = S(k)`.
2. Find the first index where `S` changes using:
   - exponential search to bracket the change
   - binary search to pinpoint the first `k'` with `S(k') > v`
3. Over the interval `[k, k'-1]`, the contribution to `T(n)` is:

`v · Σ_{i=k..k'-1} (-1)^i`

This alternating sum is:
- `0` if the interval length is even
- `(+1)` if the length is odd and `k` is even
- `(-1)` if the length is odd and `k` is odd

So each long constant interval collapses to **at most one ±v**.

This makes the total work depend on the number of “steps” in `S(k)`, which is small even up to `10^17`.

## 5) Extra speed: memoization

The interval search repeatedly evaluates `S(x)` at midpoints.
Caching computed `S(x)` values avoids recomputing the same point.

---

The provided `main.py` implements exactly this strategy and includes asserts for the sample values:

- `S(4)=7, S(10)=19, S(12)=21, S(1000)=3439`
- `T(1000)=2268`

Then it prints `T(10^17)`.
