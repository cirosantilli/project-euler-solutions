# Project Euler 648 Solution - Skipping Squares

<https://projecteuler.net/problem=648>:

* [648.py](648.py)

We have a random increasing walk starting at `s = 0`:

- with probability `ρ` we add `1`
- with probability `1−ρ` we add `2`

The process stops at the first **positive** perfect square reached (the `10^18` cap is irrelevant for the first 1000 Taylor coefficients).

Let `f(ρ)` be the expected number of squares skipped, and write its Taylor series

\[
f(\rho)=\sum_{k\ge 0} a_k \rho^k,\qquad F(n)=\sum_{k=0}^n a_k.
\]

We need `F(1000) (mod 10^9)`.

---

## 1) Turn the expectation into “skip at least m squares”

If the walk first lands on `(m+1)^2`, then exactly `m` squares were skipped (`1^2,2^2,...,m^2`).

So

\[
f(\rho) = \sum_{m\ge 1} \Pr(\text{skip at least } m \text{ squares}).
\]

For Taylor coefficients up to degree `N=1000`, only the first `N+1` terms matter because the `m`-th term starts at degree at least `m−1`.

---

## 2) Skipping a square “resets” the state (factorization)

To **skip** the square `j^2` you must cross from `j^2−1` using a `+2` step (a `+1` would land on `j^2` and stop).

Therefore, whenever `j^2` is skipped, the walk *deterministically* lands at `j^2+1`.

That means:

- after skipping `(j−1)^2`, the next segment always starts at `(j−1)^2+1`
- skipping successive squares becomes a product of per-segment probabilities (Markov property + deterministic restart)

So

\[
\Pr(\text{skip first } m \text{ squares})=\prod_{j=1}^m s_j(\rho),
\]

where `s_j(ρ)` is the probability of skipping `j^2` starting from `(j−1)^2+1`.

---

## 3) A small-distance recurrence gives each `s_j(ρ)` as a polynomial

From `(j−1)^2+1` to `j^2` the distance is:

\[
j^2 - ((j-1)^2 + 1) = 2(j-1).
\]

Let `v_k(ρ)` be the probability of skipping a square when you are `k` below it.
Then:

- `v_0 = 0` (you are on the square → you stop)
- `v_1 = 1−ρ` (from square−1 you skip only if you take `+2`)
- for `k≥2`:

\[
v_k = \rho\, v_{k-1} + (1-\rho)\, v_{k-2}.
\]

For square `j^2 (j≥2)` we need `v_{2(j-1)}`.

We compute these as **truncated polynomials in `ρ`** up to degree `1000`, all arithmetic modulo `10^9`.

---

## 4) Efficient polynomial multiplication via “big-int packing”

Naively multiplying 1000 polynomials of length ~1000 would be too slow in Python.

Key trick:

- coefficients are kept modulo `10^9`
- pack a coefficient array into a single integer in base `2^70`
- multiply integers (fast C code inside CPython: Karatsuba/FFT)
- unpack base-`2^70` digits back into coefficients

Choosing `2^70` is safe because every needed convolution coefficient is `< 2^70`, so **no carries** occur between packed digits.

This reduces the heavy work from Python loops to optimized big-integer multiplication.

---

## 5) Build `f(ρ)` only up to the needed order

Each new skipped square contributes a factor with **zero constant term**, so the `m`-th product starts at degree `m−1`.

Thus, to get coefficients up to degree `1000`, we only need products up to `m=1001`, and each multiplication is truncated appropriately.

---

## Correctness checks

The implementation asserts the values given in the statement:

- `a0 = 1`, `a1 = 0`, `a5 = −18`, `a10 = 45176`
- `F(10) = 53964`
- `F(50) ≡ 842418857 (mod 10^9)`

---

## Output

Running `main.py` prints `F(1000) mod 10^9`.
