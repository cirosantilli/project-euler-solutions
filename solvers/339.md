# Project Euler 339 Solution - Peredur Fab Efrawg

<https://projecteuler.net/problem=339>:

* [339.py](339.py)

This solution computes the optimal expected final number of black sheep, **E(n)**, for the process described in Project Euler 339, and prints **E(10 000)** rounded to 6 decimal places.

## Key ideas

### 1) Reduce the story to a 1D controlled Markov chain

Let:

- `m` = total number of sheep
- `b` = number of black sheep (so whites are `m-b`)

A bleat chooses a sheep uniformly at random:

- with probability `b/m` a black sheep bleats ⇒ one white becomes black ⇒ `b → b+1`
- with probability `(m-b)/m` a white sheep bleats ⇒ one black becomes white ⇒ `b → b-1`

After that, Peredur may **remove any number of white sheep**, i.e. decrease `m` without changing `b`.

So the entire state is just `(m, b)`.

### 2) Dynamic programming via an “optimal stopping” view (Snell envelope)

Define `S_m(b)` as the optimal expected final number of black sheep **at the decision stage**
(right after a bleat+conversion) when there are `m` total sheep and `b` black sheep.

At that point Peredur can “stop” (remove ≥1 white sheep) and drop to some smaller total `m' < m`,
or “continue” with the current `m`. Because `m` only ever decreases, the problem becomes a
nested sequence of **optimal stopping problems** as `m` grows.

### 3) Use a martingale scale function (birth–death chain potential theory)

For fixed `m`, `b` evolves as a birth–death chain with transition probabilities:

- `p_b = b/m` (up)
- `q_b = (m-b)/m` (down)

Such chains have a **scale function** `x_m(b)` that makes `x_m(b_t)` a martingale.
Here it turns out to be exactly a *binomial cumulative sum*:

\[
x_m(b)\;=\;\sum_{i=0}^{b-1}\binom{m-1}{i}
\]

(hence `x_m(m)=2^{m-1}`).

For a 1D martingale, the Snell envelope is the **least concave majorant** of the payoff when plotted
against the martingale coordinate. That gives `S_m` without iterative value-iteration.

### 4) Symmetry ⇒ the stopping region is exactly “black not strictly ahead”

In this specific problem, the least concave majorant structure plus symmetry implies:

- **Stop (remove whites) whenever** `b ≤ floor(m/2)`
- **Continue** when `b > floor(m/2)`

So:

- for `b ≤ floor(m/2)`, `S_m(b) = S_{m-1}(b)` (you immediately drop to a smaller `m`)
- for `b > floor(m/2)`, `S_m(b)` is the unique harmonic (martingale-linear) function that matches
  the boundary value at `b=floor(m/2)` and at `b=m`.

This collapses the DP to tracking only a **single diagonal** of values.

### 5) Collapse to an O(n) recurrence with central binomial probabilities

Let:

- `B[b] = S_{2b}(b)` (the “midpoint” value when total is `2b`)
- `p = C(N, N/2)/2^N` for even `N` (central binomial probability)
- `q = C(N, (N+1)/2)/2^N` for odd `N`

You can update:

- `p` with `p_{N+2} = p_N * (N+1)/(N+2)`
- `q` with `q_{N+2} = q_N * (N+2)/(N+3)`

and then compute `B[b]` in one pass:

\[
B[b] \;=\; B[b-1] + \bigl((2b-1)-B[b-1]\bigr)\cdot \frac{2p}{1+p}
\]

Finally, for the initial state `(m,b)=(2n,n)`:

\[
E(n)=\frac{1}{2}\Bigl(S_{2n}(n-1) + S_{2n}(n+1)\Bigr)
\]

where `S_{2n}(n-1)=B[n-1]` and `S_{2n}(n+1)` is one more linear step in scale space.

## Complexity

- **Time:** `O(n)` floating-point operations  
- **Memory:** `O(n)` for the `B` array (size `n+1`)

For `n=10_000` this runs essentially instantly in Python.

## Output

Running `python3 main.py` prints `E(10000)` rounded to 6 decimal places, and includes an assert for the
statement’s test value `E(5) = 6.871346`.
